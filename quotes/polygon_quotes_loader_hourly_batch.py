"""
bulk_polygon.py
---------------
–ü–∞–∫–µ—Ç–Ω–∞—è –≤—ã–≥—Ä—É–∑–∫–∞ —á–∞—Å–æ–≤—ã—Ö –∫–æ—Ç–∏—Ä–æ–≤–æ–∫ Polygon.io
–∑–∞ –ø–µ—Ä–∏–æ–¥ 2015-01-01 ‚Äî 2025-01-01 —Å –ª–∏–º–∏—Ç–æ–º 20 RPS.

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
    pip install aiohttp pandas tqdm certifi
"""

from __future__ import annotations

import asyncio
import ssl
from pathlib import Path

import aiohttp
import certifi
import pandas as pd
from aiohttp import ClientTimeout
from tqdm.asyncio import tqdm


# ===============  –ù–ê–°–¢–†–û–ô–ö–ò  =================================================

API_KEY   = "9j_C_F8fB29lulKXPysa3kSlLyuLSq_M"   # üîë –≤–∞—à –∫–ª—é—á Polygon
FROM_DATE = "2015-01-01"
TO_DATE   = "2025-01-01"
TIMESPAN  = "hour"

MAX_REQUESTS_PER_SECOND = 20        # –ª–∏–º–∏—Ç –ø–æ–¥–ø–∏—Å–∫–∏
CONCURRENT_SYMBOLS      = 50        # —Å–∫–æ–ª—å–∫–æ —Ç–∏–∫–µ—Ä–æ–≤ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
REQUEST_TIMEOUT         = 45        # —Å–µ–∫. –Ω–∞ –ª—é–±–æ–π GET (—á–∏—Ç–∞—Ç—å + –∂–¥–∞—Ç—å)

BASE_DIR   = Path(__file__).resolve().parent
OUTPUT_DIR = BASE_DIR / "data"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# ============================================================================


class RateLimiter:
    """‚â§ MAX_REQUESTS_PER_SECOND –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –ª—é–±—É—é —Å–µ–∫—É–Ω–¥—É."""
    def __init__(self, rps: int):
        self._rps = rps
        self._sem = asyncio.Semaphore(rps)
        asyncio.create_task(self._reset_loop())

    async def _reset_loop(self):
        while True:
            await asyncio.sleep(1)
            for _ in range(self._rps - self._sem._value):
                self._sem.release()

    async def __aenter__(self):
        await self._sem.acquire()

    async def __aexit__(self, exc_type, exc, tb):
        pass


async def fetch_json(session: aiohttp.ClientSession, url: str,
                     rl: RateLimiter, retries: int = 3) -> dict | None:
    """
    GET ‚Üí JSON —Å —Ç–∞–π–º-–∞—É—Ç–æ–º –∏ –ø–æ–≤—Ç–æ—Ä–∞–º–∏.
    –í–æ–∑–≤—Ä–∞—Ç None –ø—Ä–∏ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–π –Ω–µ—É–¥–∞—á–µ.
    """
    for attempt in range(retries + 1):
        try:
            async with rl:
                async with session.get(url) as resp:
                    if resp.status != 200:
                        text = await resp.text()
                        raise aiohttp.ClientError(f"{resp.status}: {text[:120]}‚Ä¶")
                    return await resp.json()

        except (aiohttp.ClientError, asyncio.TimeoutError) as e:
            if attempt == retries:
                print(f"‚ùå  {url} ‚Üí {e}")
                return None
            await asyncio.sleep(2 ** attempt)       # 1 ‚Üí 2 ‚Üí 4 —Å–µ–∫


async def download_symbol(symbol: str, session: aiohttp.ClientSession,
                          rl: RateLimiter) -> str:
    """–°–∫–∞—á–∞—Ç—å –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ–¥–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞, —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ CSV, –≤–µ—Ä–Ω—É—Ç—å —Å—Ç–∞—Ç—É—Å-—Å—Ç—Ä–æ–∫—É."""
    base = (f"https://api.polygon.io/v2/aggs/ticker/{symbol}"
            f"/range/1/{TIMESPAN}/{FROM_DATE}/{TO_DATE}"
            f"?adjusted=true&sort=asc&limit=50000&apiKey={API_KEY}")

    url, rows, pages = base, [], 0

    while url:
        data = await fetch_json(session, url, rl)
        if data is None:                           # –±–µ–∑–Ω–∞–¥—ë–∂–Ω–æ
            return f"‚ùå {symbol}: –æ—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞"

        rows.extend(data.get("results", []))
        pages += 1
        tqdm.write(f"{symbol}: —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {pages} –≥–æ—Ç–æ–≤–∞")

        next_url = data.get("next_url")
        url = f"{next_url}&apiKey={API_KEY}" if next_url else None

    if not rows:
        return f"‚ùå {symbol}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

    df = (pd.DataFrame(rows)
            .assign(datetime=lambda d: pd.to_datetime(d["t"], unit="ms"))
            .rename(columns={"o": "open", "h": "high", "l": "low",
                             "c": "close", "v": "volume"})
            .loc[:, ["datetime", "open", "high", "low", "close", "volume"]])

    outfile = OUTPUT_DIR / f"{symbol}.csv"
    df.to_csv(outfile, index=False)
    return f"‚úÖ {symbol}: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫"


async def main() -> None:
    symbols_path = BASE_DIR / "symbols.txt"
    if not symbols_path.exists():
        print("–§–∞–π–ª symbols.txt –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return
    symbols = [s.strip() for s in symbols_path.read_text().splitlines() if s.strip()]
    if not symbols:
        print("–§–∞–π–ª symbols.txt –ø—É—Å—Ç.")
        return

    ssl_ctx = ssl.create_default_context(cafile=certifi.where())
    connector = aiohttp.TCPConnector(
        ssl=ssl_ctx,
        limit=MAX_REQUESTS_PER_SECOND * 2            # —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —Å –∑–∞–ø–∞—Å–æ–º
    )
    timeout = ClientTimeout(total=REQUEST_TIMEOUT, connect=20)

    rl = RateLimiter(MAX_REQUESTS_PER_SECOND)

    async with aiohttp.ClientSession(timeout=timeout,
                                     connector=connector) as session:
        results: list[str] = []
        for i in range(0, len(symbols), CONCURRENT_SYMBOLS):
            chunk = symbols[i: i + CONCURRENT_SYMBOLS]
            tasks = [download_symbol(sym, session, rl) for sym in chunk]
            # tqdm.asyncio –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            results.extend(await tqdm.gather(*tasks, total=len(chunk)))

        print("\n--- –ò—Ç–æ–≥–∏ ---")
        for line in results:
            print(line)


if __name__ == "__main__":
    asyncio.run(main())
